---
title: "CovidCAR Package Overview"
date: "2023-05-18"
description: "CovidCAR is intended to facilitate Covid19 model building, ensembling, and evalutaion"
format:
  html:
    df-print: kable
    code-fold: show
    code-summary: "Hide code"
    code-overflow: wrap
    toc-title: Page Contents
    toc: true
    toc-depth: 2
    number-sections: false
    html-math-method: katex
    css: styles.css
    theme: flatly
    toc-location: left
    smooth-scroll: true
editor_options: 
  chunk_output_type: console
---
<style type="text/css">

body, td {
   font-size: 13pt;
}
code.r{
  font-size: 11pt;
}
pre {
  font-size: 11px
}
</style>


    
# Tutorial Overview
This tutorial briefly outlines core functions used to preprocess observation data, build spatial-temporal models, and post-process model outputs.  Its purpose is to demonstrate a standard workflow not to provide an in depth examination of model building techniques.  
   
   

# Preliminaries   
**Load needed packages**
```{r echo=TRUE, warning=FALSE, message=FALSE}
#comments and prompts
options(dplyr.summarise.inform = FALSE)
library(cli)


#wrangling
library(tidyverse)
library(lubridate)
library(arrow)
library(Hmisc)
library(yaml)

#spatial manipulation
library(sp)
library(sf)
library(spdep)
library(rgeos)
library(igraph)
library(maptools)
library(mapproj)

#census data
library(censusapi)

#inference
library(INLA) #Not available on CRAN
#install.packages("INLA",repos=c(getOption("repos"),
#INLA="https://inla.r-inla-download.org/R/stable"), dep=TRUE)

library(EpiEstim)
library(forecast)
```

[**CovidCAR**](https://github.com/JMHumphreys/CovidCAR) currently on GitHub  
```{r}
library(CovidCAR)
```

# Setup Analysis 

## Specifiy Dates and Directories 
The *setup_analysis()* function defines key date thresholds for model training and forecast horizon periods and should always be run before using any other functions in the **CovidCAR** package.  The dates are written to a yaml file for use by other functions.  
  
The function also allows for recording directory paths to (optionally) write outputs outside of the working directory or to pull previously cached observation data (cache as created with **Covid19Forecast**.v1).  
```{r}
my_ouputs <- "C:/Users/unp7/Desktop/Misc/test_CovidCAR"
my_local <- "C:/Users/unp7/Desktop/GitHub/covid19Forecasts/local/cache"

setup_analysis(report_date = "2021-08-23", #report date, first forecast day
               training_period = 2*28, #days
               forecast_horizon = 28, #days
               output_dir = my_ouputs, #write outputs here
               local_cache_dir = my_local #cache
)
```

## Define Spatial Domain
The *download_boundaries()* function pulls US State and territorial boundaries (ESRI shapefiles) from sources in the public domain.  Some basic projection is performed, the shapefile is converted to a SpatialPolygonsDataFrame, and data attributes for a location identifier ('Region') and name ('State') are appended to the object.  
  
NOTE: The function includes an option to download county boundaries (unit="county") but there are some timeout issues that need to be resolved due to large file size.     
```{r}
States <- download_boundaries(unit = "state")
class(States)
head(States@data[,c("Region", "State")]) #appended attributes  
```

## Adjacency Graph
The *get_neighbors()* function is used to identify polygons (States and Territories in this example) that are located next to each other.  Neighbor information is recorded in a matrix (dimensions: location*location) that is included with the CAR model.  Estimates for any one location are then 'conditional' on the estimates for surrounding locations.   
   
NOTE: Polygons representing locations such as Hawaii and Guam are isolated from other locations (termed 'islands') and can be problematic.  One option in this situation is to force connections between locations; the function's 'connect' option will force connections between islands and other locations based on proximity.   
   
**Example: Islands with "no links"** 
```{r warning=FALSE}
nb_islands = get_neighbors(States, connect=FALSE)
summary(nb_islands) #note that "7 regions with no links"
```
  
**Example: All locations linked**   
```{r warning=FALSE}
nb_coerced = get_neighbors(States, connect=TRUE)
summary(nb_coerced)
```

**View mapped adjacency**  
The *plot_neighbors()* function overlays adjacency connections on mapped location boundaries.    
```{r}
plot_neighbors(States, nb_islands)

plot_neighbors(States, nb_coerced)
```

**Convert to INLA Graph**
The *nb2INLA()* and *inla.read.graph()* functions are provided by the **INLA** package.  
```{r}
nb2INLA("J", nb_coerced)
J = inla.read.graph("J")
```

# Retrieve Observation Data
The *get_covid19_obs()* function downloads hospital incidence data for a specified data range.  
  
#### The *source* options for data to be retrieved:
+ The **covidcast** package  
+ From a local *cache* as created by the **covid19Forecasts** package (i.e., refactored pipeline pkg)  
+ From *test* data available from the package itself (sample from summer 2021)     
```{r warning=FALSE, message=FALSE}
MinDate = min(su_yaml$full_time_span)
MaxDate = max(su_yaml$full_time_span)

testData = get_covid19_obs(source = "covidcast", start_date = MinDate, end_date = MaxDate)
#testData = get_covid19_obs(source = "cache", start_date = MinDate, end_date = MaxDate)
#testData = get_covid19_obs(source = "test", start_date = MinDate, end_date = MaxDate)

dim(testData)
head(testData)
```

**Add Spatial Index**  
The *append_region_index()* function matches location names in the observation data to the *Region* index in the polygon boundaries object, which also corresponds with the adjaceny matrix.  The Region index is added as a column to the observations as is a new **trn_tst** column that is coded with either a **trn** or **tst** nominal indicator to distinguish time periods used for model training (observed) and testing (not observed).       
```{r}
train_data = append_region_index(train_data = testData, polys = States)
which(is.na(train_data$Region))
```


# Forecast Template
The *create_forecast_template()* function ensures that each location-time combination in the analysis is represented in the data ingested by the model.  In the case of model runs using only historic observations, this function basically returns the original input but with some column names adjusted.  This because the full date range was already represented.  However, in the case of future dates where observations are not yet available, this function will add a row for each day through the forecast horizon coding the observed incidence *value* as NA as a placeholder.    
```{r}
train_data = create_forecast_template(train_data)
```

# Additional Covariates   
Demo models in this example are fairly simple but in many cases users will want to add additional predictors, signals, or covariates (independent variables).  This section of the script demonstrates how to (1) pull and add demographic variables from the American Community Survey (ACS) and how to (2) add Rt estimates generated from the **EpiEstim** package.    
   
## Demographic Data
The *getPovertyPop()* function provides a wrapper function for the [**getCensus** package](https://centeronbudget.github.io/getcensus/) for loading American Community Survey (ACS) data from the U.S. Census Bureau.  In this example, an API key ('secret_api') is used to pull the percent of each state's total population in poverty (SAEPOVRTALL_PT) and the number of individuals over the age of 55yrs (given in the *vars_pop* option).  
```{r echo=FALSE}
secret_api = "51074e4f14daf997bb47f6ccf553a05f38e6ccb9"
```
```{r}
PovPop_data = getPovertyPop(key=secret_api, 
                            vars_pov = c("SAEPOVRTALL_PT"), 
                            vars_pop = c('AGEGROUP','POP'), filt_age = c(12,18))


train_data = left_join(train_data, PovPop_data, by = "location")
```

## Rt Estimation
The *Rt_projection()* function combines the *estimate_R()* function from the [**EpiEstim** package](https://github.com/mrc-ide/EpiEstim) with simple timeseries models to forecast Rt estimated over the model training period across the forecast horizon (28 days in the future).  Both the 'raw' Rt estimate ('Rt_raw') for the observation period only and the forecast values ('Rt') are added to the dataframe.   
  
#### Forecast models include:
+ simple ARIMA model using the **forecast** package (method="arima")    
+ an order-2 random walk with noise and trend using the **INLA** package (method="dlm)

NOTE: This is an experimental function and the "dlm" method is used as an example.  Models later in this demo will use the Rt_raw value to forecast concurrently with incidence estimation.   
```{r warning=FALSE, message=FALSE}
Rt_df = Rt_projection(train_data, mean_si = 5.7, std_si = 2, forecast_horizon = 28, method = "dlm")
```

**Rt Estimates**  
Checking *Rt_projection()* results  
```{r}
Rt_df[1:10,] #check values

Rt_df %>% 
  filter(trn_tst == "test") %>% 
  slice(1:10) #check values (forecast period)
```


# Organize Data  
Model parameters, inputs, and covariates will vary from model-to-model and user-to-user but ultimately all need to be combined in a single object that can be ingested by the the inference software, INLA in this case.   The code below modifies the train_data dataframe to perform any desired scaling and to add several spatial and temporal indices.  
  
Ordered integers are used as indices to define timesteps (days, weeks, etc), locations ('Region'), and space*time combinations (e.g., 'ID.Region.Wk' in the next chunk).  The modeling approach is hierarchical, so some indices may be used in multiple levels.  But, each index name must be unique therefore some indices are copied and given slighly different names.  

Once data is organized, it is reformatted as a list object called a 'datastack' that is passed to the inference software.  Although a daraframe might be more intuitive, a list object is used so that model inputs can be of different lengths.
   

## Clean Dataframe 
The *time_index()* function is used to recode a date vector to the desired timestep duration (2-day steps, 1 week steps, etc).  
```{r}
train_data <- as.data.frame(Rt_df) %>%
  mutate(
    s_pop = log(age_pop), #log scale
    s_pov = as.numeric(scale(SAEPOVRTALL_PT)), #some NAs present.  
    doy = as.integer(as.factor(date)),
    doy.1 = doy,
    Region.Wk = paste0("ID", Region, "W", doy), #unique Region*doy combinations ('space-time interaction')
    ID.Region.Wk = as.integer(as.factor(Region.Wk)), #convert factor levels to integer
    week = week(date),
    int_week.1 = as.integer(as.factor(week)),
    int_week.2 = int_week.1,
    int_week.3 = int_week.1,
    threeday_indx = time_index(date, seq(min(date), max(date), by = "3 days")),
    threeday_indx.1 = as.integer(as.factor(threeday_indx)),
    fourday_indx = time_index(date, seq(min(date), max(date), by = "4 days")),
    fourday_indx.1 = as.integer(as.factor(fourday_indx)),
    fiveday_indx = time_index(date, seq(min(date), max(date), by = "5 days")),
    fiveday_indx.1 = as.integer(as.factor(fiveday_indx)),
    eightday_indx = time_index(date, seq(min(date), max(date), by = "8 days")),
    eightday_indx.1 = as.integer(as.factor(eightday_indx)),
    biweek_indx = time_index(date, seq(min(date), max(date), by = "14 days")),
    biweek_indx.1 = as.integer(as.factor(biweek_indx)),
    Region.1 = Region, Region.2 = Region, Region.3 = Region, 
                Region.4 = Region, Region.5 = Region
  ) %>%
  select(c(-biweek_indx, threeday_indx, fourday_indx, fiveday_indx, eightday_indx))

head(train_data)

```

## Respone Variable  
The response variable may differ between models.  In this case, copying hospital incidence (counts) to a new column, standardizing the distribution, and ensuring that observations for the forecast horizon are coded as NA.  Retaining the scaling object and rewriting as function *obs_scale()* to transform model outputs back to the observation scale later.  
  
Again, response variables are specific to individual model setup so could be scaled differently or not at all to be fit with a different likelihood (Poisson, NegBinomial, etc).  Keeping it simple here.       
```{r}
train_data$resp = ifelse(train_data$trn_tst == "train", train_data$value, NA) #Set obs value to NA for forecasts periods

resp_scale_obj = scale(train_data$resp, scale=T, center=T) #scaled object
obs_scale = function(r)r*attr(resp_scale_obj,'scaled:scale') + attr(resp_scale_obj, 'scaled:center') #transform back to observation scale

train_data$nrm_resp = as.numeric(resp_scale_obj)
```

## Format as a Datastack  
In this example, data could remain as a dataframe and passed to INLA directly, but as a matter of practice, it is better to format as a list object (datastack).  
```{r}
nrm.lst = list(list(intercept1 = rep(1, dim(train_data)[1])), #custom intercept
          list(pov_pct = train_data[,"s_pov"],                #desired covariates and indices below
               pop = train_data[,"s_pop"],                    #formatting as nrm.lst = list()
               Rt_raw = train_data[,"Rt_raw"],
               Rt_raw.1 = train_data[,"Rt_raw"],
               Rt = train_data[,"Rt"],
               Rt.1 = train_data[,"Rt"],
               doy = train_data[,"doy"],
               doy.1 = train_data[,"doy.1"],
               doy.2 = train_data[,"doy.1"],
               int_week.1 = train_data[,"int_week.1"],
               int_week.2 = train_data[,"int_week.2"],
               int_week.3 = train_data[,"int_week.3"],
               threeday_indx.1 = train_data[,"threeday_indx.1"],
               fourday_indx.1 = train_data[,"fourday_indx.1"],
               fiveday_indx.1 = train_data[,"fiveday_indx.1"],
               eightday_indx.1 = train_data[,"eightday_indx.1"],
               biwek_indx.1 = train_data[,"biweek_indx.1"],
               Region.1 = train_data[,"Region.1"],
               Region.2 = train_data[,"Region.2"],
               Region.3 = train_data[,"Region.3"],
               Region.4 = train_data[,"Region.4"],
               Region.5 = train_data[,"Region.5"],
               Region_Wk = train_data[,"ID.Region.Wk"],
               dow = train_data[,"day"]))

nrm.stk = inla.stack(data = list(Y = train_data$nrm_resp), #Y is response variable
                                      A = list(1,1),       #option to include matrices, not used in this case
                                effects = nrm.lst,         #list object from above
                                    tag = "nrm")           #arbitrary name to index searches later 
                                                           #(multiple datastack used in complex models)
```


# Model Priors and Formulae  
Specifying all priors and formulas for desired models using [**R-INLA**](https://www.r-inla.org/) syntax.  A deep-dive would be needed to describe in detail, which would be too time consuming for this workflow focused demonstration.  
  
### A few notes:
+ Priors
  - **pc** refers to ["Penalizing Complexity"](https://doi.org/10.1214/16-STS576) 
  - **prec** is "precision"  
  - **cor** is "correlation"   
  - non-PC priors are coded using the distribution name (e.g., norm = "normal")  
+ Formulas 
  - **Y** is the response variable in the datastack
  - *f()* designates a function, level, or submodel in the hierarchy   
  - **hyper=** refers to the prior for that *f()* 

## Set Priors  
```{r}
#bym prior
bym_hyper <- list(phi = list(prior = "pc", 
                      param = c(0.5, 2/3), 
                      initial = 3), 
               prec = list(prior = "pc.prec", 
                       param = c(1, 0.01), 
                       initial = 1.5))  
#Normal prior
norm.prior <- list(theta=list(prior = "normal", param=c(0, 1)))


#iid prior
pc_prec_iid <- list(theta = list(prior="pc.prec", param=c(0.5, 0.01)))

#ar1 prior
pc_cor_ar1 <- list(theta = list(prior = 'pccor1', param = c(0.5, 0.9)))

#rw2 prior
pc_rw2 <- list(prec=list(prior="pc.prec", param=c(0.5,0.01)))

#bundle priors to archive run
priors.list <- list()
priors.list[["bym_hyper"]] <- bym_hyper
priors.list[["norm.prior"]] <- norm.prior
priors.list[["pc_prec_iid"]] <- pc_prec_iid
priors.list[["pc_cor_ar1"]] <- pc_cor_ar1
priors.list[["pc_rw2"]] <- pc_rw2
```

## Specify Formulas
**Formula 1:** Random Walk plus noise for each location (i.e., state)  
```{r}
Frm.1 = Y ~ -1 +     #remove default intercept
  intercept1 +       #custom intercept
  f(doy.1,           #order by time index (daily)
    constr=TRUE,     #enforced zero mean
    model="rw1",     #order-1 random walk with noise
    scale.model = TRUE, #additional internal scaling
    group = Region.1, #run rw1 model for groups based on location 
    control.group=list(model="iid"), #groups are treated independently
    hyper=pc_rw2)  #prior for rw2
```

**Formula 2:** Random Walk plus noise and trend for each location 
```{r}
Frm.2 = Y ~ -1 +     
  intercept1 +       
  f(doy.1,           
    constr=TRUE,     
    model="rw1",    
    scale.model = TRUE, 
    group = Region.1, 
    control.group=list(model="iid"), 
    hyper=pc_rw2) + 
  f(doy.2, model="linear", mean.linear = 0, prec.linear = 0.001) #add linear trend to rw1
```

**Formula 3:** Common spatial effect for timesteps but each location has separate autoregression 
```{r}
Frm.3 = Y ~ -1 +    
  intercept1 +       
  f(Region.1,        #location index
    model="bym2",    #spatial effect, Besag-York-Mollie model (the 2 indicates scaling) 
    graph=J,         #Adjacency graph to identify neighbors
    constr=TRUE,     #enforced zero mean
    hyper=bym_hyper) + #BYM prior
  f(doy.1,             #order by time index (daily)
    model="ar1",       #apply order-1 autoregressive
    constr=TRUE,
    group = Region.1,  #run ar1 model for groups based on location
    control.group=list(model="iid"), #groups are treated independently
    hyper=pc_cor_ar1) 
```

**Formula 4:** Separate spatial effect for each timestep (related by ar1) and each location has its own autoregressive term. 
```{r}
Frm.4 = Y ~ -1 +     
  intercept1 +       
  f(Region.1,        
    model="bym2",   
    graph=J,         
    constr=TRUE,     
    group = doy,     #time index, daily (create separate realizations of spatial covariate for each day)
    control.group=list(model="ar1"), #groups are related via an order-1 autoregressive
    hyper=bym_hyper) + #prior for BYM
  f(doy.1,             
    model="ar1",       
    constr=TRUE,
    group = Region.1,  
    control.group=list(model="iid"), 
    hyper=pc_cor_ar1) 
```

**Formula 5:** As Formula 4 but with space-time interaction to capture location and time specific variation outside of modeled trends.  
```{r}
Frm.5 = Y ~ -1 +    
  intercept1 +       
  f(Region.1,        
    model="bym2",    
    graph=J,         
    constr=TRUE,    
    group = doy,     
    control.group=list(model="ar1"),
    hyper=bym_hyper) +
  f(doy.1,             
    model="ar1",       
    constr=TRUE,
    group = Region.1,  
    control.group=list(model="iid"), 
    hyper=pc_cor_ar1) +
  f(Region_Wk,   #Index for all location*time combinations (space-time interaction)
    model="iid", #each location and time combination considered independently
    constr=TRUE,
    hyper=pc_prec_iid) 
```

**Formula 6:** As Formula 5 but adding covariate for variation due to day of week (e.g. Monday, Tuesday,...Sunday).  
```{r}
Frm.6 = Y ~ -1 +    
  intercept1 +       
  f(Region.1,        
    model="bym2",    
    graph=J,         
    constr=TRUE,     
    group = doy,     
    hyper=bym_hyper, 
    control.group=list(model="ar1")) +
  f(doy.1,             
    model="ar1",       
    constr=TRUE,
    group = Region.1,  
    control.group=list(model="iid"), 
    hyper=pc_cor_ar1) +
  f(dow,           #discrete variable indicating day of week, e.g. Monday, Tuesday,...Sunday
    constr=TRUE,
    model="iid",   #days of week may vary independently
    group = Region.2, #variation attributed to days of week may differ by location
    control.group=list(model="iid"), 
    hyper=pc_prec_iid) +
  f(Region_Wk,   
    model="iid", 
    constr=TRUE,
    hyper=pc_prec_iid) 
```

**Formula 7:** Including Rt estimates as an experimental covariate.  Forecast Rt trend estimated from the observation period (training period) to the future (28 days) using an autoregressive model.
```{r}
Frm.7 = Y ~ -1 +     
  intercept1 +       
  pov_pct + pop +    
  f(Region.1,        
    model="bym2",    
    graph=J,        
    constr=TRUE,     
    group = doy,     
    hyper=bym_hyper, 
    control.group=list(model="ar1")) + 
  f(doy.1, Rt_raw,  #order by time index (daily) but weight each timestep by corresponding Rt_raw estimate
    model="ar1",    #apply order-1 autoregressive to Rt weighted time index above
    constr=TRUE,
    group = Region.2, 
    control.group=list(model="iid"),
    hyper=pc_cor_ar1) +
  f(dow,           
    constr=TRUE,
    model="iid",
    group = Region.3,
    control.group=list(model="iid"),
    hyper=pc_prec_iid) +
  f(Region_Wk,   
    model="iid", 
    constr=TRUE,
    hyper=pc_prec_iid) 
```

**Formula 8:** As with Formula 8 but adding a random walk at a more coarse time scale (3 day steps) to reduce forecast decay.   
```{r}
Frm.8 = Y ~ -1 +     
  intercept1 +       
  pov_pct + pop +    #linear covariates for poverty and population over 55yrs
  f(Region.1,        
    model="bym2",    
    graph=J,        
    constr=TRUE,     
    group = doy,    
    hyper=bym_hyper, 
    control.group=list(model="ar1")) + 
  f(threeday_indx.1, #time index, 3days
    constr=TRUE,
    model="rw2",     #order-2 random walk with noise
    scale.model = TRUE,
    group = Region.2,
    control.group=list(model="iid"), 
    hyper=pc_rw2) + 
  f(doy.1, Rt_raw,  
    model="ar1",    
    constr=TRUE,
    group = Region.3, 
    control.group=list(model="iid"),
    hyper=pc_cor_ar1) +
  f(dow,           
    constr=TRUE,
    model="iid",
    group = Region.4,
    control.group=list(model="iid"),
    hyper=pc_prec_iid) +
  f(Region_Wk,   
    model="iid", 
    constr=TRUE,
    hyper=pc_prec_iid) 
```

**Organize Formulas**
```{r}
formulas.list <- list()
formulas.list[["base_rw1"]] <- Frm.1
formulas.list[["rw1_trend"]] <- Frm.2
formulas.list[["base_car"]] <- Frm.3
formulas.list[["car_time"]] <- Frm.4
formulas.list[["car_sti"]] <- Frm.5
formulas.list[["car_wdays"]] <- Frm.6
formulas.list[["car_rt"]] <- Frm.7
formulas.list[["car_full"]] <- Frm.8
```

# Run Models
The *run_model_list()* function runs a series of models as specified in the **formulas.list** using the input data organized as a datastack (nrm.srk).  The function runs each model sequentially and writes the executed models (models_out), formulas (formulas.list), priors (prior.list), datastack, and original dataframe (train_data) to an **.RData** in the analysis directory.  The **models_out** object will also be available in the environment for further processing.  
  
There are many customization options for inference but have opted to keep *run_model_list()* fairly simple for ease of use and maximum efficiency.  

#### Addional *run_model_list()* options:
+ **likelihood**  
  - If one likelihood is provided it will be applied to all models  
  - A vector of likelihoods can be provided with order based on **formulas.list**  
  - e.g., myFamilies <- c("gaussian", "binomial", "zeroinflatednbinomial", ...) 
+ **config** 
  - indicates if latencies (GMRF) should be retained for sampling  
  - **config=TRUE** can be time intensive and dramatically slow model runs
  - CovidCAR has a *post_sampling()* function to facilitate sampling 
+ **verbose** prints INLA algorithm process to screen during model runs   
+ **archive** indicates to save model inputs and results to the analysis directory 
  - model outputs will be written to a *run_archive* subdirectory
  
## Run All Models   
```{r warning=FALSE, message=FALSE}
formulas.list = formulas.list[c(1:4)] #short list for demo, fast run models

#formulas.list = formulas.list[3]

models_out = run_model_list(formulas.list=formulas.list,
                            dataStack=nrm.stk,
                            likelihood = "gaussian",
                            config=FALSE, verbose = FALSE, archive=TRUE)
```

# Extract and Format Forecasts
The *extract_forecasts()* function pulls forecasts from models and saves them to a *forecasts* folder in analysis directory.  The function also returns a *forecast_paths* list object to the environment with file path names.
```{r}
extract_forecasts(mod_out=models_out,
                  dataStack=nrm.stk, train_data=train_data,
                  team = "CFA")

#check returned object
names(forecast_paths)
head(read.csv(forecast_paths[["rw1_trend"]])) #formatted for submission
```


# Model Scoring

## Score Forecasts
The *score_WIS()* function calculates the WIS score for forecasts by model.  Optional arguments can be included to indicate if files should be read from a directory (ingest = "path"), a dataframe in the environment (ingest = "dataframe"),or from a list object with individual file paths (ingest = "list") as returned by *extract_forecasts()*.
  
The 'missing' option can be used to specify how missing observation data should be handled; 'remove' from data or fill with 'zero'.    
```{r}
truth_data <- train_data %>%
  select(date, location, value)

my_scores <- score_WIS(forecast_data = forecast_paths, truth=truth_data, ingest = "list", missing = "remove") 

#Example using ingest=path
#my_dir = "C:/Users/unp7/Desktop/Misc/test_CovidCAR/2021-08-23-CovidCAR-run2023-05-20/forecasts"
#my_scores = score_WIS(forecast_data = my_dir, truth=truth_data, ingest = "path") 

head(my_scores)

#overall
wis_rank <- my_scores %>%
  group_by(model) %>%
  summarise(mean_wis = mean(WIS)) %>%
  arrange(mean_wis) %>%
  mutate(wisRank = row_number())

wis_rank
```

**Diagnostic score plots**  
The *plot_WIS_lines()* function has options to make quick plots of WIS scores returned by *score_WIS()*.   
```{r}
unique(my_scores$model)

#lines showing absolute WIS
plot_WIS_lines(my_scores, by = "date", range = "abs")

#lines showing scaled WIS
plot_WIS_lines(my_scores, by = "date", range = "scaled", scale_model = "base_rw1")

#tiles with optional 'limit' that recodes: (WIS >= limit) -> limit
plot_WIS_lines(my_scores, by = "tile", range = "scaled", scale_model = "base_rw1", limit = 2)
```


# Ensemble

```{r}
my_mae <- score_MAE(forecast_data = forecast_paths, truth=truth_data, ingest = "list", missing = "remove") 

mod_rank <- left_join(my_mae, wis_rank, by="model") #combine with overall WIS

mod_rank
```

The *propose_weights()* function
```{r}
my_wis_weights <- propose_weights(forecast_data = forecast_paths, 
                             ingest = "list",
                             rank_df = mod_rank,
                             rankCol = "mean_wis",
                             team = "CFA",
                             mod_name = "wis_ensemble")

my_wis_weights

my_mae_weights <- propose_weights(forecast_data = forecast_paths, 
                             ingest = "list",
                             rank_df = mod_rank, 
                             rankCol = "MAE",
                             drop = 4,
                             team = "CFA",
                             mod_name = "mae_ensemble")
my_wis_weights
```


## Ensemble Re-scoring 
```{r}
truth_data <- train_data %>%
  select(date, location, value)

myDir <- "C:/Users/unp7/Desktop/Misc/test_CovidCAR/2021-08-23-CovidCAR-run2023-05-21/forecasts"
new_mae <- score_MAE(forecast_data = myDir, truth=truth_data, ingest = "path", missing = "remove") 
new_mae
```



## Historic Forecasts















